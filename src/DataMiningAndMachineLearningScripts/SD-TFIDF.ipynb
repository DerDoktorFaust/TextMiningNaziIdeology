{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T03:09:53.609464Z",
     "start_time": "2024-05-17T03:09:53.606364Z"
    }
   },
   "source": [
    "##########################################################################\n",
    "# Author: Christopher Thomas Goodwin\n",
    "# Creation Date: 2024.05.16\n",
    "# Summary: Uses sklearn to explore the data of the NSHWE Stimmungs- und Lageberichte files\n",
    "#          using TF-IDF and then K-Means clustering\n",
    "##########################################################################"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T03:13:29.379321Z",
     "start_time": "2024-05-17T03:13:29.370454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#### Get all file names\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "files = [] # holds file paths of all text files\n",
    "\n",
    "for file in Path(\"../../data/text\").glob(\"*.txt\"):\n",
    "    files.append(file.parent / file.name)\n",
    "\n",
    "n_files = len(files)\n",
    "print(n_files) # 750\n",
    "print(files[0]) # should have full path"
   ],
   "id": "feb5aa81c8755079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "../../data/text/1943.02.04 - Meldungen aus dem Reich Cleaned.txt\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T03:15:38.832830Z",
     "start_time": "2024-05-17T03:15:38.795917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#### convert all text files into strings\n",
    "docs = [] # holds string version of each file (i.e. each text file converted into one string and stored here\n",
    "\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        contents = f.read()\n",
    "    docs.append(contents)\n",
    "    f.close()"
   ],
   "id": "1857f53849b2d6c9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T03:25:33.147675Z",
     "start_time": "2024-05-17T03:25:31.765084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#### run TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "german_stop_words = stopwords.words('german')\n",
    "additional_stop_words = [\"volk\", \"volksgemeinschaft\", \"1939\", \"1940\", \"1941\", \"1942\", \"1943\", \"1944\", \"1945\", \"deutsch\", \"bev√∂lkerung\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"einzelmeldungen\", \"volksgenossen\", \"sei\", \"seien\", \"worden\", \"meldungen\", \"deutsche\", \"deutschen\", \"wegen\", \"wurde\", \"gif\", \"pro\", \"kg\", \"minusbox\", \"images\", \"rm\"]\n",
    "\n",
    "for i in range(0, 1946):\n",
    "    additional_stop_words.append(str(i))\n",
    "\n",
    "german_stop_words.extend(additional_stop_words)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.90, min_df=5, stop_words=german_stop_words, use_idf=True, norm=None)\n",
    "transformed_documents = vectorizer.fit_transform(docs)\n",
    "transformed_documents_array = transformed_documents.toarray()\n",
    "print(len(transformed_documents_array)) # should match the number above to make sure we transformed all documents\n",
    "\n"
   ],
   "id": "94cae13bca1b5a5f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cgoodwin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T03:30:51.445477Z",
     "start_time": "2024-05-17T03:30:32.548475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#### output TF-IDF scores\n",
    "import pandas as pd\n",
    "\n",
    "Path(\"data/tf-idf_output\").mkdir(parents=True, exist_ok=True) # make directory if it doesn't already exist\n",
    "\n",
    "output_filenames = [str(file).replace(\".txt\", \".csv\").replace(\"../../data/text\", \"data/tf-idf_output\") for file in files]\n",
    "\n",
    "for counter, doc in enumerate(transformed_documents_array):\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names_out(), doc))\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    one_doc_as_df.to_csv(output_filenames[counter])\n"
   ],
   "id": "c438354b70bbfb7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tf-idf_output/1942.09.25 - Meldungen aus dem Reich Cleaned.csv\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
