{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9eebbea6367738c",
   "metadata": {},
   "source": [
    "# BERTopic Exploration of the Stimmmungs- und Lageberichte Database Files\n",
    "**Author:** Christopher Thomas Goodwin\n",
    "\n",
    "**Creation Date:** 2024.04.10\n",
    "\n",
    "**Summary:** Uses BERTopic modelling to explore the data of the NSHWE Stimmungs- und Lageberichte files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32d9a89f70746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from bertopic import BERTopic\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Get stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Check if GPU acceleration is available and call appropriate libraries\n",
    "import GPUtil\n",
    "\n",
    "if len(GPUtil.getAvailable()) > 0:\n",
    "    from cuml.cluster import HDBSCAN\n",
    "    from cuml.manifold import UMAP\n",
    "    print(\"GPU engaged.\")\n",
    "else:\n",
    "    from umap import UMAP\n",
    "    from hdbscan import HDBSCAN\n",
    "    print(\"No GPU engaged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b681f81e40e3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which platform user is on and set the data path accordingly\n",
    "if platform.system() == \"Linux\":\n",
    "    path = \"/home/cgoodwin/PycharmProjects/TextMiningNaziIdeology/data/json/stimmungs_data_sentences.json\"\n",
    "elif platform.system() == \"Darwin\":\n",
    "    path = \"/Users/cgoodwin/Programming Projects/TextMiningNaziIdeology/data/json/stimmungs_data_sentences.json\"\n",
    "else:\n",
    "    path = \"C:\\\\Users\\\\Christopher Goodwin\\\\Documents\\\\Programming Projects\\\\TextMiningNaziIdeology\\\\data\\\\json\\\\stimmungs_data_sentences.json\"\n",
    "    \n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    files = json.load(f)\n",
    "    # files loaded in as dictionary with strings of 0... length of files\n",
    "    \n",
    "    # we want just the textual data, the report from each entry\n",
    "    reports = []\n",
    "    for i in range(len(files)):\n",
    "        reports.append(files[str(i)][\"report\"]) # iterate through dictionary and append report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0c2b8c2936ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up vectorizer for German stopwords\n",
    "german_stop_words = stopwords.words('german')\n",
    "additional_stop_words = [\"volk\", \"volksgemeinschaft\", \"1939\", \"1940\", \"1941\", \"1942\", \"1943\", \"1944\", \"1945\", \"deutsch\", \"bev√∂lkerung\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"einzelmeldungen\", \"volksgenossen\", \"sei\", \"seien\", \"worden\", \"meldungen\", \"deutsche\", \"deutschen\", \"wegen\", \"wurde\", \"gif\", \"pro\", \"kg\", \"minusbox\", \"images\", \"rm\"]\n",
    "\n",
    "for i in range(0, 1946):\n",
    "    additional_stop_words.append(str(i))\n",
    "\n",
    "german_stop_words.extend(additional_stop_words)\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=german_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517a6c0066c782d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Adjust UMAP and HDBSCAN parameters\n",
    "umap_model = UMAP(n_components=5, n_neighbors=10, min_dist=0.2)\n",
    "hdbscan_model = HDBSCAN(min_samples=5, min_cluster_size=5, prediction_data=True)\n",
    "\n",
    "# Initialize BERTopic with adjusted models\n",
    "topic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model, embedding_model=\"paraphrase-multilingual-MiniLM-L12-v2\", language=\"multilingual\", vectorizer_model=vectorizer_model, verbose=True, nr_topics=10, top_n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167cd9e1ea07ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968646d520c3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491dccec5f0d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e224f6c7e6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680519dca268321",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"my_model\", serialization=\".safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f16f14",
   "metadata": {},
   "source": [
    "# Generative Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def query_ollama(prompt, model=\"gemma3:12b\", temperature=0.1):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    response = requests.post(url, json={\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"stream\": False\n",
    "    })\n",
    "    \n",
    "    return response.json()['response'].strip()\n",
    "\n",
    "top_topic_ids = topic_model.get_topic_info().head(10)['Topic'].tolist()\n",
    "\n",
    "topic_keywords = {topic_id: topic_model.get_topic(topic_id) for topic_id in top_topic_ids}\n",
    "\n",
    "custom_labels = {}\n",
    "\n",
    "\n",
    "for topic_id, keywords in topic_keywords.items():\n",
    "    words = ', '.join([word for word, _ in keywords])\n",
    "    prompt = f\"Give these keywords: {words}, generate a short, descriptive topic label that summarizes the theme. All of the topics come from the period 1939 to 1945 and are related to the Sicherheitsdienst in Nazi Germany. They are the ones who wrote the reports.\"\n",
    "    label = query_ollama(prompt)\n",
    "    custom_labels[topic_id] = label\n",
    "    print(f\"Topic {topic_id}: {label}\")\n",
    "    \n",
    "# Copy existing labels\n",
    "topic_model.custom_labels_ = topic_model.get_topic_info()['Name'].tolist()\n",
    "\n",
    "# Replace with new ones\n",
    "\n",
    "for topic_id, label in custom_labels.items():\n",
    "    if topic_id < len(topic_model.custom_labels_):\n",
    "        topic_model.custom_labels_[topic_id] = label\n",
    "        \n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4e12cf6bc8617",
   "metadata": {},
   "source": [
    "# Apply TF-IDF to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d6dc5e6463a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, stop_words=german_stop_words)\n",
    "embeddings = tfidf_vectorizer.fit_transform(reports)\n",
    "\n",
    "tfidf_model = BERTopic(nr_topics=75)\n",
    "tfidf_topics, tfidf_probs = tfidf_model.fit(reports, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b492a8aa208e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.get_topic_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMiningNaziIdeology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
