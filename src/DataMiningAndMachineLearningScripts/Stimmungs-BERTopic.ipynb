{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# BERTopic Exploration of the Stimmmungs- und Lageberichte Database Files\n",
    "**Author:** Christopher Thomas Goodwin\n",
    "\n",
    "**Creation Date:** 2024.04.10\n",
    "\n",
    "**Summary:** Uses BERTopic modelling to explore the data of the NSHWE Stimmungs- und Lageberichte files"
   ],
   "id": "a9eebbea6367738c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T01:34:27.698788Z",
     "start_time": "2024-04-12T01:34:27.443484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bertopic import BERTopic\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import GPUtil\n",
    "from cuml.cluster import HDBSCAN\n",
    "from cuml.manifold import UMAP\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ],
   "id": "2a32d9a89f70746f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cgoodwin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T01:35:43.502622Z",
     "start_time": "2024-04-12T01:35:43.203685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"/Users/cgoodwin/Documents/Programming/Python/NSHWEDatabaseMining/data/json/stimmungs_data_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    files = json.load(f)\n",
    "    # files loaded in as dictionary with strings of 0... length of files\n",
    "    \n",
    "    # we want just the textual data, the report from each entry\n",
    "    reports = []\n",
    "    for i in range(len(files)):\n",
    "        reports.append(files[str(i)][\"report\"]) # iterate through dictionary and append report"
   ],
   "id": "7b681f81e40e3385",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T01:35:46.306838Z",
     "start_time": "2024-04-12T01:35:46.302278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up vectorizer for German stopwords\n",
    "german_stop_words = stopwords.words('german')\n",
    "vectorizer_model = CountVectorizer(stop_words=german_stop_words)"
   ],
   "id": "ebe0c2b8c2936ce9",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T01:40:27.641399Z",
     "start_time": "2024-04-12T01:40:27.602805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for GPU to run model faster\n",
    "if len(GPUtil.getAvailable()) > 0:\n",
    "    print(\"GPU engaged.\")\n",
    "    \n",
    "    # create instances of GPU-accelerated UMAP and HDBSCAN\n",
    "    umap_model = UMAP(n_components=2, n_neighbors=15, min_dist=0.0)\n",
    "    hdbscan_model = HDBSCAN(min_samples=10, gen_min_span_tree=True, prediction_data=True)\n",
    "    topic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model, embedding_model=\"paraphrase-multilingual-MiniLM-L6-v2\", vectorizer_model=vectorizer_model, language=\"multilingual\")\n",
    "else:\n",
    "    print(\"No GPU engaged.\")\n",
    "    \n",
    "    # use multilingual model and apply German stopwords vectorizer model\n",
    "    topic_model = BERTopic(embedding_model=\"paraphrase-multilingual-MiniLM-L12-v2\", vectorizer_model=vectorizer_model, language=\"multilingual\", nr_topics=50)"
   ],
   "id": "1517a6c0066c782d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU engaged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topics, probs = topic_model.fit_transform(reports)",
   "id": "167cd9e1ea07ff4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topic_model.get_topic_info()",
   "id": "1968646d520c3872",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topic_model.get_topic(44)",
   "id": "2491dccec5f0d18c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
