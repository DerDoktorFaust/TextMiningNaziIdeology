{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9eebbea6367738c",
   "metadata": {},
   "source": [
    "# BERTopic Exploration of the Stimmmungs- und Lageberichte Database Files\n",
    "**Author:** Christopher Thomas Goodwin\n",
    "\n",
    "**Creation Date:** 2024.04.10\n",
    "\n",
    "**Summary:** Uses BERTopic modelling to explore the data of the NSHWE Stimmungs- und Lageberichte files"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a32d9a89f70746f",
   "metadata": {},
   "source": [
    "import platform\n",
    "from bertopic import BERTopic\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "\n",
    "# Get stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Check if GPU acceleration is available and call appropriate libraries\n",
    "import GPUtil\n",
    "\n",
    "if len(GPUtil.getAvailable()) > 0:\n",
    "    from cuml.cluster import HDBSCAN\n",
    "    #from cuml.manifold import UMAP # GPU-based version of UMAP\n",
    "    from umap import UMAP # use CPU-based version of UMAP which is better for noisy or duplicate data\n",
    "    print(\"GPU engaged.\")\n",
    "\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"Current GPU device index: {torch.cuda.current_device()}\")\n",
    "    print(f\"Current GPU device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    print(f\"Pytorch Cuda version: {torch.version.cuda}\")\n",
    "else:\n",
    "    from umap import UMAP\n",
    "    from hdbscan import HDBSCAN\n",
    "    print(\"No GPU engaged.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7b681f81e40e3385",
   "metadata": {},
   "source": [
    "# Check which platform user is on and set the data path accordingly\n",
    "print(f\"The Operating System is {platform.system()}\")\n",
    "\n",
    "if platform.system() == \"Linux\":\n",
    "    path = \"/home/cgoodwin/Documents/Programming/TextMiningNaziIdeology/data/json/stimmungs_data_sentences.json\"\n",
    "elif platform.system() == \"Darwin\":\n",
    "    path = \"/Users/cgoodwin/Programming Projects/TextMiningNaziIdeology/data/json/stimmungs_data_sentences.json\"\n",
    "else:\n",
    "    path = \"C:\\\\Users\\\\Christopher Goodwin\\\\Documents\\\\Programming Projects\\\\TextMiningNaziIdeology\\\\data\\\\json\\\\stimmungs_data_sentences.json\"\n",
    "    \n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    files = json.load(f)\n",
    "    # files loaded in as dictionary with strings of 0... length of files\n",
    "    \n",
    "    # we want just the textual data, the report from each entry\n",
    "    reports = []\n",
    "    for i in range(len(files)):\n",
    "        reports.append(files[str(i)][\"report\"]) # iterate through dictionary and append report\n",
    "\n",
    "print(\"File loaded.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ebe0c2b8c2936ce9",
   "metadata": {},
   "source": [
    "# set up vectorizer for German stopwords\n",
    "german_stop_words = stopwords.words('german')\n",
    "additional_stop_words = [\"volk\", \"volksgemeinschaft\", \"1939\", \"1940\", \"1941\", \"1942\", \"1943\", \"1944\", \"1945\", \"deutsch\", \"bev√∂lkerung\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"einzelmeldungen\", \"volksgenossen\", \"sei\", \"seien\", \"worden\", \"meldungen\", \"deutsche\", \"deutschen\", \"wegen\", \"wurde\", \"gif\", \"pro\", \"kg\", \"minusbox\", \"images\", \"rm\"]\n",
    "\n",
    "for i in range(0, 1946):\n",
    "    additional_stop_words.append(str(i))\n",
    "\n",
    "german_stop_words.extend(additional_stop_words)\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=german_stop_words)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1517a6c0066c782d",
   "metadata": {},
   "source": [
    " # Adjust UMAP and HDBSCAN parameters\n",
    "umap_model = UMAP(n_components=5, n_neighbors=10, min_dist=0.2)\n",
    "hdbscan_model = HDBSCAN(min_samples=5, min_cluster_size=5, prediction_data=True)\n",
    "\n",
    "# Initialize BERTopic with adjusted models\n",
    "topic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model, embedding_model=\"paraphrase-multilingual-MiniLM-L12-v2\", language=\"multilingual\", vectorizer_model=vectorizer_model, verbose=True, nr_topics=15, top_n_words=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "167cd9e1ea07ff4d",
   "metadata": {},
   "source": [
    "topics, probs = topic_model.fit_transform(reports)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1968646d520c3872",
   "metadata": {},
   "source": [
    "topic_model.get_topic_info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2491dccec5f0d18c",
   "metadata": {},
   "source": [
    "topic_model.get_topic(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed3e224f6c7e6b73",
   "metadata": {},
   "source": [
    "topic_model.visualize_barchart()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a680519dca268321",
   "metadata": {},
   "source": [
    "topic_model.save(\"my_model\", serialization=\".safetensors\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9f16f14",
   "metadata": {},
   "source": [
    "# Generative Labeling"
   ]
  },
  {
   "cell_type": "code",
   "id": "6384bdfe",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "def query_ollama(prompt, model=\"gemma3:12b\", temperature=0.3): # options: gemma3:12b; qwen3:30b; deepseek-r1:14b; gpt-oss:20b\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    response = requests.post(url, json={\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"stream\": False\n",
    "    })\n",
    "    \n",
    "    return response.json()['response'].strip()\n",
    "\n",
    "top_topic_ids = topic_model.get_topic_info().head(10)['Topic'].tolist()\n",
    "\n",
    "topic_keywords = {topic_id: topic_model.get_topic(topic_id) for topic_id in top_topic_ids}\n",
    "\n",
    "custom_labels = {}\n",
    "\n",
    "\n",
    "for topic_id, keywords in topic_keywords.items():\n",
    "    words = ', '.join([word for word, _ in keywords])\n",
    "    prompt = f\"Give these keywords: {words}, generate a short, descriptive topic label that summarizes the theme.\"\n",
    "    label = query_ollama(prompt)\n",
    "    custom_labels[topic_id] = label\n",
    "    print(f\"Topic {topic_id}: {label}\")\n",
    "    \n",
    "# Copy existing labels\n",
    "topic_model.custom_labels_ = topic_model.get_topic_info()['Name'].tolist()\n",
    "\n",
    "# Replace with new ones\n",
    "\n",
    "for topic_id, label in custom_labels.items():\n",
    "    if topic_id < len(topic_model.custom_labels_):\n",
    "        topic_model.custom_labels_[topic_id] = label\n",
    "        \n",
    "topic_model.visualize_topics()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acf4e12cf6bc8617",
   "metadata": {},
   "source": [
    "# Apply TF-IDF to Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c5d6dc5e6463a93",
   "metadata": {},
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, stop_words=german_stop_words)\n",
    "embeddings = tfidf_vectorizer.fit_transform(reports)\n",
    "\n",
    "tfidf_model = BERTopic(nr_topics=75)\n",
    "tfidf_topics, tfidf_probs = tfidf_model.fit(reports, embeddings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d0b492a8aa208e9",
   "metadata": {},
   "source": [
    "tfidf_model.get_topic_info()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMiningNaziIdeology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
